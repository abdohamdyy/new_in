# -*- coding: utf-8 -*-
"""
equivalents_search.py

ğŸ” Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø¨Ø­Ø« (Querying Order):
1) Ù†Ø¨Ø­Ø« Ø¨Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ÙØ¹Ù‘Ø§Ù„Ø© Ø£ÙˆÙ„Ù‹Ø§ (active_ingredients) + scientific hint
2) Ø«Ù… Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¹Ù„Ù…ÙŠ ÙÙ‚Ø·
3) Ø«Ù… Ø§Ù„Ø§Ø³Ù… Ø§Ù„ØªØ¬Ø§Ø±ÙŠ/Ø§Ù„Ø§Ø³Ù… (brand/commercial)
(Ø§Ù„ØªØ±ÙƒÙŠØ² Ù„Ø§ ÙŠÙØ³ØªØ®Ø¯Ù… ÙÙŠ Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹.. Ù‡Ù†Ø³ØªØ®Ø¯Ù…Ù‡ Ù„Ø§Ø­Ù‚Ù‹Ø§ ÙÙŠ Ø§Ù„ÙØ±Ø²)

ğŸ“Š Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ÙØ±Ø² (Ranking in response):
- Ø£ÙˆÙ„Ø§Ù‹: Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¹Ù„Ù…ÙŠÙ‹Ø§ (active/scientific â‰¥ 0.70)
- Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø±ØªØ¨Ø·ÙŠÙ† Ø¹Ù„Ù…ÙŠÙ‹Ø§: Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø±Ù‚Ù… ØªØ±ÙƒÙŠØ² ÙŠØ³Ø§ÙˆÙŠ target_mg "Ø¨Ø§Ù„Ø¸Ø¨Ø·"
- Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ: ØªØ±ØªÙŠØ¨ Ø¹Ø§Ø¯ÙŠ Ø­Ø³Ø¨ final_score (vector + fuzzy: active > scientific > brand)
- Ø«Ù… tie-break Ø¨Ø§Ù„Ù€ base_score10

ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ù†ÙØ³ Ø£Ø³Ù„ÙˆØ¨ drug_search.py:
- normalize_ar
- distance_to_score10
- Ù†ÙØ³ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø®Ø±Ø¬: id/query/base_score10/final_score/bonus/tag/.../meta/doc
"""

from __future__ import annotations
import re
import unicodedata
import difflib
from typing import List, Dict, Any, Optional, Tuple

import chromadb
from chromadb.config import Settings
from langchain_huggingface import HuggingFaceEmbeddings
from config import Config

# ======================= Ø«ÙˆØ§Ø¨Øª ÙˆØ£ÙˆØ²Ø§Ù† =======================
# Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø¨ÙˆÙ†ØµØ§Øª: Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ÙØ¹Ù‘Ø§Ù„Ø© Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„Ø¹Ù„Ù…ÙŠØŒ ÙˆØ§Ù„Ø¹Ù„Ù…ÙŠ Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„ØªØ¬Ø§Ø±ÙŠ
ACTIVE_FUZZY_MIN        = 0.70
ACTIVE_BASE_BOOST       = 1.4
ACTIVE_STRONG_BOOST     = 1.6   # r>=0.90

SCIENTIFIC_FUZZY_MIN    = 0.70
SCIENTIFIC_BASE_BOOST   = 1.0
SCIENTIFIC_STRONG_BOOST = 1.2   # r>=0.90

BRAND_FUZZY_MIN         = 0.70
BRAND_BASE_BOOST        = 0.7
BRAND_STRONG_BOOST      = 1.0   # r>=0.90 Ø£Ùˆ Ø·ÙˆÙ„ Ù‚Ø±ÙŠØ¨

# Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¯ÙˆØ§Ø¦ÙŠ
FORM_MATCH_BONUS        = 0.6   # strict=True
FORM_SOFT_BONUS         = 0.2   # strict=False

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ù…Ù† Chroma
DEFAULT_EQ_TOP_K        = 800
DEFAULT_MIN_BASE10      = 0.0

# Ø¹ØªØ¨Ø© Ø§Ø¹ØªØ¨Ø§Ø± Ø§Ù„Ù†ØªÙŠØ¬Ø© "Ù…Ø±ØªØ¨Ø·Ø© Ø¹Ù„Ù…ÙŠÙ‹Ø§"
RELEVANT_MIN            = 0.70

# ======================= ØªØ·Ø¨ÙŠØ¹ ÙˆØ£Ø¯ÙˆØ§Øª Ø¹Ø§Ù…Ø© =======================
_ARABIC_DIACRITICS = re.compile(r"[\u0610-\u061A\u064B-\u065F\u0670\u06D6-\u06DC\u06DF-\u06ED]")
AR_CHARS = "Ø¡-ÙŠ"
_NON_WORD = re.compile(rf"[^\w{AR_CHARS}]+", re.UNICODE)

def normalize_ar(text: str) -> str:
    if not isinstance(text, str):
        return ""
    text = unicodedata.normalize("NFKC", text)
    text = _ARABIC_DIACRITICS.sub("", text)
    text = (text.replace("Ø£","Ø§").replace("Ø¥","Ø§").replace("Ø¢","Ø§")
                 .replace("Ù‰","ÙŠ").replace("Ø©","Ù‡")
                 .replace("Ø¤","Ùˆ").replace("Ø¦","ÙŠ"))
    return re.sub(r"\s+", " ", text).strip().lower()

def distance_to_score10(d: Optional[float]) -> float:
    """Ø­ÙˆÙ‘Ù„ Ù…Ø³Ø§ÙØ© ÙƒÙˆØ³Ø§ÙŠÙ† (0..2) Ø¥Ù„Ù‰ Ø¯Ø±Ø¬Ø© 0..10 (Ù†ÙØ³ drug_search)."""
    if d is None:
        return 0.0
    s = (1.0 - (d / 2.0)) * 10.0
    return max(0.0, min(10.0, float(s)))

# ======================= Active / Scientific =======================
_SPLIT_ACTIVE = re.compile(r"[,\+\-/\(\)\[\]{}Ø›;ØŒ]|(?:\s+Ùˆ\s+)|(?:\s+and\s+)", re.IGNORECASE)

def extract_active_tokens(meta: Dict[str, Any]) -> List[str]:
    """ÙŠØ³ØªØ®Ø±Ø¬ ØªÙˆÙƒÙ†Ø² Ù…Ù† Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ÙØ¹Ù‘Ø§Ù„Ø© + ÙŠØ¹ÙŠØ¯ Ø§Ù„Ø¹Ù„Ù…ÙŠ ÙƒØªÙˆÙƒÙÙ† Ù…Ø³ØªÙ‚Ù„."""
    parts_active = []
    v1 = (meta or {}).get("active_ingredients") or (meta or {}).get("Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ÙØ¹Ø§Ù„Ø©")
    if isinstance(v1, str) and v1.strip():
        parts_active.append(v1)

    tokens_active: List[str] = []
    if parts_active:
        text = " ØŒ ".join(parts_active)
        raw_tokens = [t.strip() for t in _SPLIT_ACTIVE.split(text) if t and t.strip()]
        for t in raw_tokens:
            tn = normalize_ar(t)
            if len(tn) >= 2:
                tokens_active.append(tn)

    sci = (meta or {}).get("scientific_name") or (meta or {}).get("Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¹Ù„Ù…ÙŠ") or ""
    sci_norm = normalize_ar(sci) if isinstance(sci, str) else ""

    return tokens_active + ([sci_norm] if sci_norm else [])

def best_active_fuzzy_ratio(meta: Dict[str, Any], q_norm: str) -> Tuple[float, str]:
    """Ø£ÙØ¶Ù„ ØªØ·Ø§Ø¨Ù‚ ÙØ²ÙŠ Ø¶Ù…Ù† (Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ÙØ¹Ù‘Ø§Ù„Ø© + Ø§Ù„Ø¹Ù„Ù…ÙŠ ÙƒØªÙˆÙƒÙÙ†)."""
    toks = extract_active_tokens(meta)
    best = 0.0
    best_tok = ""
    for t in toks:
        r = difflib.SequenceMatcher(None, t, q_norm).ratio()
        if r > best:
            best = r
            best_tok = t
    return best, best_tok

def fuzzy_ratio_on_scientific_only(meta: Dict[str, Any], q_norm: str) -> float:
    sci = (meta or {}).get("scientific_name") or (meta or {}).get("Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¹Ù„Ù…ÙŠ") or ""
    sci_norm = normalize_ar(sci) if isinstance(sci, str) else ""
    if not sci_norm or not q_norm:
        return 0.0
    return difflib.SequenceMatcher(None, sci_norm, q_norm).ratio()

# ======================= Brand / Commercial =======================
NAME_KEYS = [
    "commercial_name", "Ø§Ù„Ø§Ø³Ù… Ø§Ù„ØªØ¬Ø§Ø±ÙŠ", "Ø§Ù„Ø§Ø³Ù…_Ø§Ù„ØªØ¬Ø§Ø±ÙŠ",
    "name", "Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ù„Ø£ØµÙ„ÙŠ",
    "scientific_name", "Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¹Ù„Ù…ÙŠ",
]
def best_brand_field(meta: Dict[str, Any]) -> str:
    for k in NAME_KEYS:
        val = (meta or {}).get(k)
        if isinstance(val, str) and val.strip():
            return val
    return ""

def brand_best_token_ratio(brand: str, q_norm: str) -> Tuple[float, str, float]:
    """ÙØ²ÙŠ Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ ØªÙˆÙƒÙ† Ù…Ù† Ø§Ù„Ø§Ø³Ù… Ø§Ù„ØªØ¬Ø§Ø±ÙŠ + Ø¹Ù‚ÙˆØ¨Ø© Ø·ÙˆÙ„ Ø®ÙÙŠÙØ©."""
    v = normalize_ar(brand)
    if not v or not q_norm:
        return 0.0, "", 1.0
    tokens = [t for t in _NON_WORD.split(v) if t]
    best = (0.0, "", 1.0)
    for t in tokens:
        ratio = difflib.SequenceMatcher(None, t, q_norm).ratio()
        rel_extra = max(0, len(t) - len(q_norm)) / max(len(t), 1)
        penalty = 1.0 - min(0.30, rel_extra)  # 0.7..1.0
        if t.startswith(q_norm) or t.endswith(q_norm):
            ratio = min(1.0, ratio + 0.05)
        if ratio * penalty > best[0] * best[2]:
            best = (ratio, t, penalty)
    return best

# ======================= Ø§Ù„ØªØ±ÙƒÙŠØ² (Ø£Ø±Ù‚Ø§Ù… ÙÙ‚Ø·) =======================
NUM_PATTERN = re.compile(r"\d+(?:\.\d+)?")

def grab_all_numbers(text: str) -> List[float]:
    if not text:
        return []
    return [float(x) for x in NUM_PATTERN.findall(str(text))]

def collect_concentration_texts(meta: Dict[str, Any]) -> str:
    """
    Ù†Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªØ­ØªÙˆÙŠ Ø£Ø±Ù‚Ø§Ù… ØªØ±ÙƒÙŠØ²:
      - concentrations/Ø§Ù„ØªØ±Ø§ÙƒÙŠØ²
      - name/Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ù„Ø£ØµÙ„ÙŠ
      - active_ingredients/Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ÙØ¹Ø§Ù„Ø©
      - dosage/Ø§Ù„Ø¬Ø±Ø¹Ø© Ø§Ù„Ù…Ø¹ØªØ§Ø¯Ø©
    """
    parts = []
    for k in ("concentrations", "Ø§Ù„ØªØ±Ø§ÙƒÙŠØ²",
              "name", "Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ù„Ø£ØµÙ„ÙŠ",
              "active_ingredients", "Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ÙØ¹Ø§Ù„Ø©",
              "dosage", "Ø§Ù„Ø¬Ø±Ø¹Ø© Ø§Ù„Ù…Ø¹ØªØ§Ø¯Ø©"):
        v = (meta or {}).get(k)
        if isinstance(v, str) and v.strip():
            parts.append(v)
    return " | ".join(parts)

def find_number_near_active(text: str, active_norm: str, window: int = 25) -> Optional[float]:
    """
    Ù†Ø­Ø§ÙˆÙ„ Ù†Ù„Ù‚Ø· Ø±Ù‚Ù… Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¯Ø§Ø®Ù„ Ù†Ø§ÙØ°Ø© Ø­Ø±ÙˆÙ.
    Ù…Ø«Ø§Ù„: '... Ø¨Ø§Ø±Ø§Ø³ÙŠØªØ§Ù…ÙˆÙ„ (500 Ù…Ø¬Ù…) ...' â†’ Ù†Ù„ØªÙ‚Ø· 500.
    """
    if not text or not active_norm:
        return None
    t = normalize_ar(str(text))
    for m in re.finditer(re.escape(active_norm), t):
        start, end = m.span()
        l_ctx = max(0, start - window)
        r_ctx = min(len(t), end + window)
        ctx = t[l_ctx:r_ctx]
        nums = grab_all_numbers(ctx)
        if nums:
            return nums[0]
    return None

def has_exact_concentration(meta: Dict[str, Any], active_norm: str, target_mg: float) -> Tuple[bool, Optional[float]]:
    """
    true Ù„Ùˆ Ù„Ù‚ÙŠÙ†Ø§ Ø±Ù‚Ù… ÙŠØ³Ø§ÙˆÙŠ target_mg:
      - Ø£ÙˆÙ„Ù‹Ø§: Ø±Ù‚Ù… Ù…Ù„Ø§ØµÙ‚ Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ù„Ùˆ Ø£Ù…ÙƒÙ†)
      - ÙˆØ¥Ù„Ø§: Ø£ÙŠ Ø±Ù‚Ù… Ø¹Ø§Ù… ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø¬Ù…Ù‘Ø¹Ø©
    """
    if target_mg <= 0:
        return False, None
    conc_text = collect_concentration_texts(meta)
    # Ø­Ø§ÙˆÙ„ Ø±Ù‚Ù… Ù…Ù„Ø§ØµÙ‚ Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø§Ø¯Ø©
    near = find_number_near_active(conc_text, active_norm)
    if near is not None and abs(near - target_mg) < 1e-6:
        return True, near
    # ÙˆØ¥Ù„Ø§: Ø£ÙŠ Ø±Ù‚Ù… Ø¹Ø§Ù… ÙŠØ³Ø§ÙˆÙŠ Ø§Ù„Ù‡Ø¯Ù
    for n in grab_all_numbers(conc_text):
        if abs(n - target_mg) < 1e-6:
            return True, n
    return False, near

# ======================= EquivalentsFinder =======================
class EquivalentsFinder:
    """
    - Ø§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹: Active/Scientific Ø£ÙˆÙ„Ù‹Ø§ â†’ Scientific-only â†’ Brand
    - Ø§Ù„ÙØ±Ø² Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: Ø§Ù„Ù…Ø±ØªØ¨Ø· Ø¹Ù„Ù…ÙŠÙ‹Ø§ Ø£ÙˆÙ„Ù‹Ø§ØŒ Ø«Ù… exact concentration matchØŒ Ø«Ù… final_score
    """

    def __init__(
        self,
        collection_name: str = Config.COLLECTION_NAME,
        db_dir: str = Config.DB_DIRECTORY,
        top_k: int = DEFAULT_EQ_TOP_K,
        min_base10: float = DEFAULT_MIN_BASE10,
    ) -> None:
        self.collection_name = collection_name
        self.db_dir = db_dir
        self.top_k = top_k
        self.min_base10 = min_base10

        self.client = chromadb.PersistentClient(
            path=db_dir,
            settings=Settings(
                persist_directory=db_dir,
                anonymized_telemetry=False,
                allow_reset=True,
                is_persistent=True,
            )
        )
        self.collection = self.client.get_collection(collection_name)

        self.emb = HuggingFaceEmbeddings(
            model_name=Config.EMBEDDING_SETTINGS['model_name'],
            model_kwargs=Config.EMBEDDING_SETTINGS['model_kwargs'],
            encode_kwargs=Config.EMBEDDING_SETTINGS['encode_kwargs'],
        )

    # ---------- Queries Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ ----------
    def _query_active_first(self, q: str) -> Dict[str, Any]:
        q_emb = self.emb.embed_query(f"active ingredients or scientific: {q}")
        return self.collection.query(
            query_embeddings=[q_emb],
            n_results=self.top_k,
            include=["distances", "metadatas", "documents"],
        )

    def _query_scientific_only(self, q: str) -> Dict[str, Any]:
        q_emb = self.emb.embed_query(f"scientific name: {q}")
        return self.collection.query(
            query_embeddings=[q_emb],
            n_results=self.top_k,
            include=["distances", "metadatas", "documents"],
        )

    def _query_brand(self, q: str) -> Dict[str, Any]:
        q_emb = self.emb.embed_query(f"brand or commercial name: {q}")
        return self.collection.query(
            query_embeddings=[q_emb],
            n_results=self.top_k,
            include=["distances", "metadatas", "documents"],
        )

    # ---------- Ø§Ù„Ù…Ø¬Ø±Ù‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ----------
    def find_equivalents(
        self,
        active_query: str,
        target_mg: float,
        tolerance_mg: float = 0.0,   # Ù…ÙˆØ¬ÙˆØ¯ Ù„Ù„ØªÙˆØ§ÙÙ‚ ÙÙ‚Ø·
        allow_per_ml: bool = True,   # Ù…ÙˆØ¬ÙˆØ¯ Ù„Ù„ØªÙˆØ§ÙÙ‚ ÙÙ‚Ø·
        target_form: Optional[str] = None,
        strict_form: bool = True,
        limit: int = 50,
        debug: bool = False,
    ) -> List[Dict[str, Any]]:
        """
        - ÙŠØ³ØªØ±Ø¬Ø¹ Ù…Ø±Ø´Ø­ÙŠÙ† Ù…Ù† 3 Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù…Ø±ØªÙ‘Ø¨Ø© (active â†’ scientific â†’ brand)
        - ÙŠØ¨Ù†ÙŠ ØªØ¬Ù…ÙŠØ¹Ø© Ù…ÙˆØ­Ù‘Ø¯Ø© Ù„Ù„Ù…Ø±Ø´Ø­ÙŠÙ† (Ø£ÙØ¶Ù„ Ù…Ø³Ø§ÙØ© base Ù„ÙƒÙ„ id)
        - ÙŠØ­Ø³Ø¨ bonus (active/scientific/brand + form)
        - ÙŠÙØ±Ø² Ø£Ø®ÙŠØ±Ù‹Ø§ ÙƒØ§Ù„ØªØ§Ù„ÙŠ:
            (1) Ø§Ù„Ù…Ø±ØªØ¨Ø· Ø¹Ù„Ù…ÙŠÙ‹Ø§ Ø£ÙˆÙ„Ù‹Ø§ (active/scientific â‰¥ RELEVANT_MIN)
            (2) Ø¯Ø§Ø®Ù„Ù‡Ù…: exact concentration match = True
            (3) Ø«Ù… final_score Ø£Ø¹Ù„Ù‰
            (4) tie-break: base_score10 Ø£Ø¹Ù„Ù‰
        """
        if not active_query:
            return []

        # 1) Ø§Ø¬Ù…Ø¹ Ù…Ø±Ø´Ø­ÙŠÙ† Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨
        q_active   = self._query_active_first(active_query)
        q_science  = self._query_scientific_only(active_query)
        q_brand    = self._query_brand(active_query)

        pools = [q_active, q_science, q_brand]

        # 2) Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ†: Ø§Ø®ØªØ± "Ø£ÙØ¶Ù„" (Ø£ØµØºØ± Ù…Ø³Ø§ÙØ© â‡’ Ø£Ø¹Ù„Ù‰ base_score10) Ù„ÙƒÙ„ id
        merged: Dict[str, Dict[str, Any]] = {}  # id -> {dist, meta, doc}
        for res in pools:
            ids   = res.get("ids", [[]])[0]
            dists = res.get("distances", [[]])[0]
            metas = res.get("metadatas", [[]])[0]
            docs  = res.get("documents", [[]])[0]
            for _id, dist, meta, doc in zip(ids, dists, metas, docs):
                if _id not in merged or (dist is not None and dist < merged[_id]["dist"]):
                    merged[_id] = {"dist": dist, "meta": meta, "doc": doc}

        q_norm = normalize_ar(active_query)

        # 3) Ø§Ø¨Ù†Ù Ø§Ù„ØµÙÙˆÙ Ù…Ø¹ Ø§Ù„Ø¨ÙˆÙ†ØµØ§Øª (Ø¨Ø¯ÙˆÙ† Ø¨ÙˆÙ†Øµ ØªØ±ÙƒÙŠØ² â€” Ø³Ù†Ø³ØªØ®Ø¯Ù…Ù‡ Ù„Ù„ÙØ±Ø² ÙÙ‚Ø·)
        rows: List[Dict[str, Any]] = []
        for _id, pack in merged.items():
            dist = pack["dist"]
            meta = pack["meta"]
            doc  = pack["doc"]

            base_score = distance_to_score10(dist)
            if base_score < self.min_base10:
                continue

            tag_parts: List[str] = []
            bonus = 0.0

            # Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¯ÙˆØ§Ø¦ÙŠ
            is_ok, soft_bonus = form_matches(meta, target_form, strict_form)
            if not is_ok:
                continue
            if target_form and soft_bonus:
                bonus += FORM_MATCH_BONUS if strict_form else FORM_SOFT_BONUS
                tag_parts.append("form_match")

            # Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ÙØ¹Ù‘Ø§Ù„Ø©
            a_ratio, a_tok = best_active_fuzzy_ratio(meta, q_norm)
            if a_ratio >= ACTIVE_FUZZY_MIN:
                bonus += ACTIVE_BASE_BOOST * a_ratio
                if a_ratio >= 0.90:
                    bonus += ACTIVE_STRONG_BOOST
                    tag_parts.append("active_strong_fuzzy")
                else:
                    tag_parts.append(f"active_fuzzy({a_ratio:.2f})")
            else:
                tag_parts.append("active_miss")

            # Ø§Ù„Ø¹Ù„Ù…ÙŠ ÙÙ‚Ø·
            sci_ratio = fuzzy_ratio_on_scientific_only(meta, q_norm)
            if sci_ratio >= SCIENTIFIC_FUZZY_MIN:
                bonus += SCIENTIFIC_BASE_BOOST * sci_ratio
                if sci_ratio >= 0.90:
                    bonus += SCIENTIFIC_STRONG_BOOST
                    tag_parts.append("sci_strong_fuzzy")
                else:
                    tag_parts.append(f"sci_fuzzy({sci_ratio:.2f})")
            else:
                tag_parts.append("sci_miss")

            # Ø§Ù„ØªØ¬Ø§Ø±ÙŠ (Ø£Ù‚Ù„ ÙˆØ²Ù†)
            brand = best_brand_field(meta)
            b_ratio, b_token, b_pen = brand_best_token_ratio(brand, q_norm)
            if b_ratio >= BRAND_FUZZY_MIN:
                bonus += BRAND_BASE_BOOST * b_ratio * b_pen
                if b_ratio >= 0.90 or (b_token and abs(len(b_token) - len(q_norm)) <= 1):
                    bonus += BRAND_STRONG_BOOST
                    tag_parts.append("brand_strong_fuzzy")
                else:
                    tag_parts.append("brand_fuzzy")
            else:
                tag_parts.append("brand_miss")

            # ÙØ­Øµ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø¹Ù„Ù…ÙŠ Ø§Ù„Ø¹Ø§Ù…:
            is_relevant = (a_ratio >= RELEVANT_MIN) or (sci_ratio >= RELEVANT_MIN)

            # ÙØ­Øµ Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø¹Ø¯Ø¯ÙŠ Ù„Ù„ØªØ±ÙƒÙŠØ² (Ù„Ù„ÙØ±Ø² ÙÙ‚Ø·ØŒ ÙˆØ¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø±ØªØ¨Ø·ÙŠÙ† Ø¹Ù„Ù…ÙŠÙ‹Ø§ ÙÙ‚Ø·)
            active_norm = q_norm
            conc_exact, conc_num = (False, None)
            if is_relevant:
                conc_exact, conc_num = has_exact_concentration(meta, active_norm, target_mg)

            row = {
                "id": _id,
                "query": active_query,
                "base_score10": round(base_score, 3),
                "final_score": round(base_score + bonus, 3),
                "bonus": round(bonus, 3),
                "tag": "+".join(tag_parts) if tag_parts else "vector_only",
                "brand": brand or None,
                "name": (meta or {}).get("name") or (meta or {}).get("Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ù„Ø£ØµÙ„ÙŠ"),
                "commercial_name": brand or (meta or {}).get("commercial_name") or (meta or {}).get("Ø§Ù„Ø§Ø³Ù… Ø§Ù„ØªØ¬Ø§Ø±ÙŠ"),
                "scientific_name": (meta or {}).get("scientific_name") or (meta or {}).get("Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¹Ù„Ù…ÙŠ"),
                "manufacturer": (meta or {}).get("manufacturer") or (meta or {}).get("Ø§Ù„Ø´Ø±ÙƒØ© Ø§Ù„Ù…ØµÙ†Ø¹Ø©"),
                "meta": meta,
                "doc": doc,
                # Ù…ÙØ§ØªÙŠØ­ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„ÙØ±Ø² Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:
                "_relevant": is_relevant,
                "_conc_exact": bool(conc_exact) if is_relevant else False,
                "_conc_num": conc_num,
            }
            rows.append(row)

        # 4) Ø§Ù„ÙØ±Ø² Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:
        #   - Ø§Ù„Ù…Ø±ØªØ¨Ø·ÙˆÙ† Ø¹Ù„Ù…ÙŠÙ‹Ø§ Ø£ÙˆÙ„Ø§Ù‹
        #   - Ø¯Ø§Ø®Ù„Ù‡Ù…: Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚ÙˆÙ† ÙÙŠ Ø§Ù„ØªØ±ÙƒÙŠØ²
        #   - Ø«Ù…: final_score Ø£Ø¹Ù„Ù‰
        #   - Ø«Ù…: base_score10 Ø£Ø¹Ù„Ù‰
        rows.sort(key=lambda x: (
            0 if x.get("_relevant") else 1,
            0 if x.get("_conc_exact") else 1,
            -(x["final_score"]),
            -(x["base_score10"])
        ))

        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹ + limit
        for r in rows:
            r.pop("_relevant", None)
            r.pop("_conc_exact", None)
            r.pop("_conc_num", None)

        if limit:
            rows = rows[:limit]
        return rows

# ====== Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¯ÙˆØ§Ø¦ÙŠ (Ù†ÙØ¹ÙŠØ¯ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ Ù‡Ù†Ø§) ======
def form_matches(meta: Dict[str, Any], target_form: Optional[str], strict_form: bool) -> Tuple[bool, bool]:
    """ÙŠØ±Ø¬Ø¹ (is_ok, soft_bonus_flag)"""
    if not target_form:
        return True, False
    mform = (meta or {}).get("pharma_form") or (meta or {}).get("Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¯ÙˆØ§Ø¦ÙŠ") or ""
    if not isinstance(mform, str):
        mform = str(mform or "")
    nf = normalize_ar(target_form)
    mf = normalize_ar(mform)
    if not nf:
        return True, False
    if mf == nf or nf in mf or mf in nf:
        return True, True
    return (False, False) if strict_form else (True, True)
